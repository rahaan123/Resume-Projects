{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uI9el9uCztS"
   },
   "source": [
    "# Project 1 code\n",
    "\n",
    "small: 3 mins 30s\n",
    "\n",
    "Medium: 42 mins\n",
    "\n",
    "Large: 45 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ymzDPyODRp1",
    "outputId": "6fe25146-efbd-47c2-c258-15945e36de6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k_list': [20, 24, 24, 20, 19, 20, 24, 19, 20, 17, 21, 24, 23, 20, 20, 19, 18, 22, 24, 17, 21, 21, 21, 21, 21, 22, 22, 21, 21, 20, 21, 20, 20, 21, 17, 21, 21, 20, 20, 19, 19, 19, 20, 20, 20, 19, 20, 19, 20, 20, 12, 10, 12, 10, 7, 9, 10, 13, 8, 11, 12, 12, 12, 7, 12, 11, 13, 10, 13, 10, 10, 10, 10, 15, 11, 11, 10, 10, 12, 10, 10, 11, 13, 11, 13, 9, 10, 8, 11, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10], 'last_points_lists': [[30, 46, 69, 92, 121, 137, 155, 177, 203, 226, 246, 256, 261, 270, 287, 297, 316, 338, 351, 361], [30, 33, 95, 135, 143, 166, 185, 213, 231, 246, 267, 284, 306, 317, 321, 330, 332, 351, 359, 375, 388, 397, 399, 404], [10, 16, 25, 83, 125, 147, 150, 156, 181, 195, 208, 222, 227, 238, 262, 276, 283, 295, 301, 306, 327, 339, 374, 389], [9, 54, 71, 99, 111, 118, 126, 141, 157, 173, 189, 211, 231, 256, 283, 301, 319, 336, 366, 387], [38, 48, 64, 104, 151, 168, 177, 184, 198, 208, 223, 240, 265, 282, 294, 303, 311, 328, 352], [52, 92, 114, 129, 133, 177, 185, 199, 225, 246, 279, 306, 325, 331, 355, 404, 407, 417, 433, 445], [18, 23, 29, 34, 46, 85, 90, 125, 145, 155, 188, 190, 204, 227, 238, 259, 295, 299, 320, 323, 349, 367, 384, 411], [39, 48, 52, 80, 109, 131, 149, 176, 204, 232, 238, 251, 278, 303, 323, 335, 357, 393, 403], [6, 38, 70, 90, 108, 129, 131, 141, 159, 184, 186, 194, 277, 299, 329, 355, 372, 402, 416, 429], [85, 103, 152, 196, 223, 245, 254, 257, 264, 294, 317, 320, 334, 347, 359, 370, 380], [16, 47, 49, 96, 130, 143, 162, 189, 192, 202, 229, 246, 257, 274, 290, 326, 353, 369, 394, 410, 432], [33, 60, 71, 83, 104, 133, 159, 170, 184, 201, 211, 235, 248, 276, 294, 314, 319, 341, 355, 370, 391, 411, 422, 429], [26, 56, 78, 108, 121, 136, 153, 172, 192, 205, 228, 242, 250, 279, 293, 295, 308, 332, 340, 342, 352, 368, 383], [41, 71, 95, 109, 133, 172, 217, 231, 243, 247, 267, 286, 288, 299, 309, 336, 339, 350, 375, 420], [60, 72, 87, 100, 109, 123, 136, 169, 172, 181, 199, 215, 217, 247, 262, 279, 298, 326, 350, 368], [38, 73, 85, 95, 119, 161, 175, 203, 207, 226, 251, 263, 289, 305, 320, 335, 345, 371, 387], [52, 73, 79, 105, 119, 135, 164, 180, 198, 216, 232, 259, 281, 303, 332, 343, 389, 413], [46, 62, 97, 123, 148, 172, 175, 185, 224, 253, 259, 264, 287, 297, 323, 343, 356, 362, 368, 386, 390, 404], [27, 63, 71, 86, 96, 121, 134, 137, 145, 149, 175, 177, 181, 208, 228, 242, 255, 257, 282, 287, 325, 348, 363, 409], [15, 61, 72, 114, 136, 159, 189, 220, 231, 261, 277, 289, 315, 338, 352, 372, 386], [9, 34, 50, 62, 86, 100, 126, 139, 158, 179, 191, 214, 241, 258, 268, 287, 305, 328, 355, 378, 385], [16, 46, 69, 94, 116, 142, 168, 196, 208, 229, 258, 268, 278, 291, 295, 307, 324, 343, 367, 387, 405], [25, 47, 74, 104, 120, 134, 150, 170, 195, 212, 218, 224, 240, 270, 282, 299, 320, 340, 357, 379, 408], [19, 39, 60, 77, 87, 104, 133, 143, 159, 174, 186, 205, 215, 230, 259, 272, 279, 293, 323, 351, 376], [15, 21, 63, 79, 97, 123, 145, 159, 171, 185, 190, 209, 224, 250, 262, 291, 309, 327, 345, 371, 398], [55, 68, 84, 95, 105, 122, 148, 158, 181, 196, 199, 221, 244, 255, 282, 284, 314, 339, 367, 383, 405, 419], [3, 22, 45, 71, 81, 100, 110, 135, 153, 175, 194, 215, 242, 245, 259, 273, 290, 304, 329, 345, 361, 378], [26, 51, 74, 88, 111, 128, 154, 172, 184, 202, 229, 259, 286, 288, 321, 345, 361, 375, 380, 392, 418], [29, 48, 58, 68, 75, 83, 93, 113, 129, 153, 176, 201, 218, 238, 259, 288, 299, 323, 342, 364, 382], [41, 67, 90, 101, 116, 136, 159, 165, 184, 200, 229, 256, 268, 289, 305, 329, 358, 383, 404, 429], [29, 53, 69, 89, 94, 117, 142, 158, 170, 197, 208, 225, 239, 261, 289, 305, 322, 340, 366, 377, 387], [23, 37, 42, 93, 119, 122, 137, 148, 161, 182, 193, 213, 231, 245, 265, 280, 300, 310, 329, 350], [10, 23, 46, 61, 78, 89, 113, 139, 141, 175, 185, 196, 209, 224, 249, 279, 294, 310, 329, 353], [14, 32, 58, 81, 92, 111, 121, 151, 172, 194, 237, 243, 257, 270, 282, 298, 314, 331, 348, 364, 368], [39, 54, 67, 94, 123, 139, 181, 211, 236, 251, 281, 297, 318, 335, 361, 411, 421], [19, 44, 63, 86, 89, 100, 129, 149, 165, 194, 222, 237, 267, 286, 312, 327, 344, 364, 382, 407, 429], [23, 35, 60, 89, 109, 124, 145, 168, 192, 220, 240, 251, 275, 297, 323, 349, 369, 391, 416, 419, 443], [43, 78, 93, 120, 122, 152, 176, 199, 224, 254, 277, 296, 298, 315, 340, 370, 386, 403, 416, 446], [21, 40, 51, 71, 89, 109, 122, 143, 169, 181, 200, 217, 242, 253, 267, 272, 282, 307, 330, 344], [24, 58, 87, 98, 116, 136, 160, 182, 195, 219, 249, 272, 290, 303, 333, 360, 370, 382, 411], [15, 36, 76, 95, 112, 123, 145, 175, 200, 215, 225, 251, 265, 293, 311, 330, 344, 369, 397], [11, 29, 83, 98, 123, 140, 155, 179, 201, 227, 245, 269, 291, 313, 325, 350, 373, 398, 423], [13, 23, 47, 60, 88, 103, 122, 147, 157, 187, 213, 237, 255, 270, 282, 292, 302, 318, 330, 349], [12, 31, 42, 70, 88, 107, 136, 165, 179, 197, 224, 239, 265, 283, 313, 333, 346, 361, 373, 403], [13, 39, 64, 77, 103, 126, 144, 159, 180, 194, 220, 249, 270, 299, 327, 342, 353, 382, 403, 414], [14, 37, 47, 75, 87, 114, 126, 146, 163, 178, 202, 221, 245, 264, 290, 313, 324, 342, 369], [27, 43, 72, 98, 121, 146, 164, 174, 195, 208, 228, 256, 281, 291, 321, 336, 366, 380, 400, 429], [15, 42, 79, 91, 108, 129, 151, 164, 189, 219, 247, 276, 303, 313, 323, 351, 369, 379, 392], [29, 56, 74, 102, 128, 141, 153, 175, 196, 222, 235, 246, 264, 294, 311, 321, 347, 376, 398, 410], [12, 24, 36, 58, 84, 100, 117, 135, 165, 189, 219, 234, 249, 261, 273, 294, 310, 336, 359, 386], [39, 62, 78, 100, 103, 116, 121, 143, 155, 158, 177, 204], [43, 52, 55, 60, 80, 110, 139, 150, 163, 175], [49, 73, 75, 101, 126, 130, 132, 156, 191, 206, 213, 221], [20, 24, 50, 67, 93, 153, 191, 193, 204, 219], [33, 52, 114, 124, 140, 161, 184], [53, 61, 108, 115, 121, 142, 155, 183, 196], [16, 40, 42, 52, 79, 97, 112, 128, 146, 179], [28, 46, 61, 70, 82, 105, 122, 127, 157, 173, 178, 180, 199], [31, 47, 64, 89, 114, 137, 167, 205], [20, 27, 51, 87, 93, 105, 113, 123, 142, 171, 186], [10, 30, 54, 83, 96, 101, 115, 139, 145, 175, 202, 232], [7, 19, 26, 69, 71, 101, 108, 136, 159, 183, 200, 226], [40, 43, 50, 54, 90, 95, 115, 127, 137, 157, 161, 172], [28, 64, 88, 122, 138, 162, 177], [45, 53, 61, 63, 81, 99, 101, 109, 127, 149, 163, 183], [27, 53, 73, 99, 107, 131, 150, 164, 175, 202, 226], [27, 36, 49, 62, 92, 122, 124, 133, 160, 171, 181, 192, 194], [52, 61, 77, 94, 107, 131, 147, 170, 197, 218], [7, 25, 47, 52, 74, 85, 112, 134, 139, 152, 159, 161, 187], [6, 22, 48, 66, 98, 118, 126, 130, 144, 174], [12, 28, 38, 65, 87, 117, 137, 152, 162, 179], [20, 42, 55, 76, 100, 127, 147, 170, 198, 227], [38, 49, 61, 88, 115, 138, 164, 188, 199, 222], [3, 22, 30, 33, 49, 75, 92, 96, 102, 123, 137, 166, 184, 207, 222], [24, 26, 66, 96, 122, 147, 157, 167, 182, 194, 207], [13, 39, 69, 86, 105, 128, 152, 165, 168, 192, 217], [11, 34, 44, 56, 66, 80, 108, 121, 132, 160], [11, 31, 54, 84, 97, 112, 124, 138, 154, 174], [27, 53, 55, 73, 92, 109, 136, 166, 186, 197, 205, 215], [17, 39, 69, 99, 120, 130, 160, 184, 214, 224], [23, 48, 71, 92, 116, 142, 154, 170, 182, 200], [9, 30, 44, 64, 94, 115, 134, 139, 166, 180, 205], [17, 45, 62, 78, 106, 111, 113, 133, 145, 151, 162, 190, 217], [22, 45, 59, 74, 81, 87, 115, 126, 153, 174, 198], [25, 51, 79, 95, 100, 118, 143, 149, 153, 170, 183, 212, 229], [21, 31, 43, 72, 98, 125, 151, 174, 201], [16, 26, 52, 68, 78, 93, 119, 149, 166, 185], [22, 97, 125, 140, 153, 175, 186, 211], [13, 34, 46, 60, 75, 92, 101, 110, 138, 165, 177], [10, 22, 38, 63, 91, 112, 142, 161, 189, 213], [26, 75, 100, 116, 141, 158, 182, 204, 217], [21, 42, 57, 84, 103, 123, 144, 154, 176, 204], [27, 54, 82, 93, 108, 118, 140, 170, 199, 224], [18, 48, 63, 89, 118, 134, 144, 170, 183, 202], [19, 40, 57, 82, 100, 111, 126, 155, 169, 185], [9, 36, 60, 88, 102, 120, 140, 158, 177, 204], [20, 47, 76, 99, 126, 155, 179, 195, 209, 230], [26, 38, 60, 87, 99, 127, 147, 175, 192, 215], [22, 43, 66, 91, 104, 128, 153, 168, 195, 225], [10, 28, 49, 60, 70, 99, 124, 143, 158, 170]], 'OPT_list': [42269.54635643265, 48322.673294139895, 49593.58037010119, 45178.95197032229, 43483.832649705146, 52440.28875861296, 52370.79688294989, 47841.77601614363, 52267.77856979765, 43205.34566361784, 47848.99899513881, 55867.3335437418, 45388.16544990444, 47449.32943593671, 44749.39065208135, 45995.81952035597, 45988.9780853383, 50107.77229322324, 55007.45932080006, 42398.83692593682, 566.4018182509813, 532.1112056430823, 545.259212895068, 549.7920160299388, 551.4939975232517, 560.4714908418796, 532.7370441631647, 566.6884004921094, 507.4070679555981, 558.9527509496296, 519.6983039616938, 516.5551846936239, 450.3947563894784, 520.9725122945099, 549.0598248449611, 549.3602507594226, 596.1843318911754, 531.4242691662407, 485.95110155894184, 571.1951106498902, 19.543609728762895, 19.049046983691927, 20.0, 20.0, 20.0, 19.089363869246593, 20.0, 19.68878953124382, 20.0, 20.0, 25084.225441874187, 21443.912108591387, 26953.318624581018, 24264.55535857646, 19824.175950416025, 23255.643918767644, 22435.623588263807, 24514.42183964535, 23159.279064420232, 22293.853428732567, 30057.426985058442, 28329.274484922084, 24893.911520466725, 18935.341134205206, 24871.762876490524, 26961.112024093534, 23729.70872428915, 25737.955641371904, 25068.099046087045, 21729.364363999804, 267.3834997955944, 273.59944626059877, 284.8340286521792, 347.4909729019496, 296.95869922805923, 299.37068615970213, 203.0295462565042, 255.47146822828287, 338.8200674021306, 262.04642000201255, 291.1502648225909, 281.2884469341931, 296.82667925974044, 286.274322910755, 337.01228175033464, 273.3616727375496, 254.6982158651912, 271.96350879688873, 243.35705876752107, 271.02378829156487, 9.29476733040812, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0]}\n"
     ]
    }
   ],
   "source": [
    "def calc_err(x, y, m, c):\n",
    "    return np.sum((y - (m * x + c)) ** 2)\n",
    "\n",
    "def get_list(X):\n",
    "    last_points = [0] * (len(X))\n",
    "    last_points[0] = len(X[0]) - 1\n",
    "    for i in range(1, len(X)):\n",
    "        last_points[i] = last_points[i - 1] + (len(X[i]))\n",
    "    return last_points[:len(X)]\n",
    "\n",
    "def multi_line_fit(n, X_list, y_list, C):\n",
    "    if n == 0:\n",
    "        return 0, [], [], 0\n",
    "\n",
    "    err = np.zeros((n, n))\n",
    "    segment_errors = 0.0  # List to store errors for each segment\n",
    "    dyp = np.full(n + 1, np.inf)\n",
    "    segm_split = [0] * (n + 1)\n",
    "    dyp[0] = 0\n",
    "    X_val = np.array(X_list)\n",
    "    y_val = np.array(y_list)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            X = X_val[i:j + 1]\n",
    "            y = y_val[i:j + 1]\n",
    "            Xm = np.mean(X)\n",
    "            ym = np.mean(y)\n",
    "            den = np.dot(X - Xm, X - Xm)\n",
    "            num = np.dot(X - Xm, y - ym)\n",
    "\n",
    "            if num == 0 or den == 0:\n",
    "                slope = 0\n",
    "            else:\n",
    "                slope = num / den\n",
    "            intersect = ym - (slope * Xm)\n",
    "\n",
    "            err[i][j] = calc_err(X, y, slope, intersect)\n",
    "\n",
    "    for j in range(1, n + 1):\n",
    "        for i in range(1, j + 1):\n",
    "            cost = dyp[i - 1] + err[i - 1][j - 1] + C\n",
    "            if dyp[j] > cost:\n",
    "                dyp[j] = cost\n",
    "                segm_split[j] = i\n",
    "\n",
    "    X_segm = []\n",
    "    y_segm = []\n",
    "    v = n\n",
    "    while v > 0:\n",
    "        i = segm_split[v]\n",
    "        X_segm.insert(0, X_list[i - 1:v])\n",
    "        y_segm.insert(0, y_list[i - 1:v])\n",
    "        segment_errors += err[i - 1][v - 1]  # Save the error for this segment\n",
    "        v = i - 1\n",
    "\n",
    "    return len(X_segm), X_segm, y_segm, segment_errors  # Return segment_errors\n",
    "\n",
    "'''\n",
    "--------------------------------------------------------------------------------\n",
    "Code starts below. Above are all supporting functions\n",
    "--------------------------------------------------------------------------------\n",
    "Note:\n",
    "When running the program locally on PC, please mention the entire file path of\n",
    "file or the relative path from root of the current run time.\n",
    "\n",
    "If its performed on google colab, please upload the said instance files on\n",
    "google colab and give path from runtime base to file location.\n",
    "\n",
    "Below I have included the path of example_of_small_instances as an example if it\n",
    "was uploaded on google colab as mentionned above.\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"/examples_of_small_instances\"\n",
    "data = pickle.load(open(data_path, 'rb'))\n",
    "\n",
    "N_list = data['n_list']\n",
    "X_list = data['x_list']\n",
    "y_list = data['y_list']\n",
    "C_list = data['C_list']\n",
    "\n",
    "K = []\n",
    "last_points_list = []\n",
    "OPT_list = []\n",
    "\n",
    "for a in range(len(N_list)):\n",
    "    K_a, X_seg, y_seg, segment_errors = multi_line_fit(N_list[a], X_list[a], y_list[a], C_list[a])\n",
    "    last_points_list.append(get_list(X_seg))\n",
    "    OPT_list.append(segment_errors + (C_list[a] * K_a))\n",
    "    K.append(K_a)\n",
    "\n",
    "Output = dict({\n",
    "    'k_list': K,\n",
    "    'last_points_lists': last_points_list,\n",
    "    'OPT_list': OPT_list\n",
    "})\n",
    "\n",
    "'''\n",
    "Below is generation of output file, please aff proper file path for where you\n",
    "would like the desired output dump file to be created.\n",
    "If you use the output path like I have, then your output file should be created\n",
    "in the same level as root and content folder in runtime files on google colab\n",
    "'''\n",
    "# File path for output dump file\n",
    "output_file_path = \"/example_small_solutions.pkl\"\n",
    "\n",
    "# Save the data to the pickle file\n",
    "with open(output_file_path, \"wb\") as path:\n",
    "  pickle.dump(Output, path)\n",
    "\n",
    "# Load the data from the pickle file\n",
    "with open(output_file_path, \"rb\") as path:\n",
    "    loaded_data = pickle.load(path)\n",
    "print(loaded_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
